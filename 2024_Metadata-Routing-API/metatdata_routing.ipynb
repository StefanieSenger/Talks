{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Scikit-learn's Metadata Routing API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Metadata?\n",
    "\n",
    "- definition of metadata:\n",
    "    - metadata can be any data, that we want to apply on top of our tabular data, without it necessarily being part of it\n",
    "    - alternative: metadata is any data, that some object or function in a data science \"pipeline/process\" handles besides from X and y; it's a param that influences this \"step's\" treatment of the data\n",
    "\n",
    "- examples for metadata:\n",
    "    - classical examples you might know from scikit-learn: sample_weight and groups\n",
    "    - but other libraries offer support for other kinds of metadata\n",
    "    - (graphically show some other examples of metadata: gender, race, sex, zipcode, .... and area/library it is used in)\n",
    "    - self defined metadata to be used in custom metrics (and possibly custom estimators)\n",
    "\n",
    "- use cases for metadata:\n",
    "    - sample_weight and groups can be used to balance data out and prevent data leakage\n",
    "    - fairness related use case\n",
    "    - business logic\n",
    "\n",
    "- definition of routing:\n",
    "    - routing just means that we pass metadata around (or through uninvolved steps) in a data science pipeline/process to where it is used/consumed\n",
    "\n",
    "- before metadata routing API:\n",
    "    - we were limited to where sample_weight was defined because it was the only param defined in the metrics (other than y_true and y_pred)\n",
    "    - we could not consistently use it if we were using the metric in a larger structure\n",
    "\n",
    "- with metadata routing API:\n",
    "    - we can pass sample_weight and groups through several levels of estimators and pipes in scikit-learn\n",
    "    - we can combine objects from other libraries with scikit-learn estimators while still passing their metadata\n",
    "    - we can define our own custom metrics using self defined metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Passing metadata without the routing API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  race  severity  medication  recovery_time\n",
       "0    1   17     1         4           1             10\n",
       "1    0   32     0         8           1             22\n",
       "2    1   82     0         2           1             90\n",
       "3    1   27     1         9           0             32\n",
       "4    0   54     0         5           0              5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\"sex\":[1,0,1,1,0], \"age\":[17,32,82,27,54], \"race\":[1,0,0,1,0], \"severity\":[4,8,2,9,5], \"medication\":[1,1,1,0,0], \"recovery_time\":[10,22,90,32,5]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].to_numpy()\n",
    "y = data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- example: medical study on the effectiveness of a treatment\n",
    "    - we would want to group the hospitals using the groups parameter scikit-learn offers\n",
    "        - since a hospital is a collection of patients\n",
    "        - we suspect that each hospital’s data may have systematic biases due to factors like medical devices, policies, socioeconomic status of the patients, ...\n",
    "    - same hospital should not be both in the train and in the test set\n",
    "    - groups is an array of length n_samples that assigns each sample into a group and it is used in splitters exclusively, to make sure that if patterns exist within the data, we don’t leak the patterns between train and test set, because we want to train our models on the targets and not on other patterns within the data\n",
    "\n",
    "    - before we had to do a groupKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# more real data\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X = rng.rand(200, 5)\n",
    "y = rng.randint(0, 2, size=X.shape[0])\n",
    "\n",
    "groups = rng.randint(0, 10, size=X.shape[0])\n",
    "sample_weight = rng.rand(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00129414, 0.00083709]),\n",
       " 'score_time': array([0.00055003, 0.000489  ]),\n",
       " 'test_score': array([-0.27150562, -0.26527336])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = GroupKFold(n_splits=2)\n",
    "\n",
    "cross_validate(Ridge(), X, y, groups=groups, cv=cv, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- but what if we also want to pass sample_weight?\n",
    "\n",
    "- we would use sample_weight when we want to draw the attention of the machine learning algorithm to a specific group of samples, that our data under-represents in some way\n",
    "\n",
    "- in our example talking about a medical study on the effectiveness of a treatment, sample_weight might\n",
    "    - encode sex or race or the patient (to balance out data) \n",
    "    - or if we suspect a correlation between a feature an the fact if a patient got the new treatment we are interested in, e.g. a bias in which patient was chosen for the treatment, then sample_weight could be used to counter-balance that\n",
    "\n",
    "- there are several methods to determine sample_weight (from calculating proportions or more enhanced statistics from the data, or using more general statistical principles or natural laws that we know will take effect)\n",
    "- in general, we are interested to train our model on fair data in determining the efficiency of a treatment on future patients (even if past data was not gathered from a randomized trial, but is messy real world data instead)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----------------------------------------\n",
    "older ideas of what sample_weight is:\n",
    "- when do we want to pass sample_weight?\n",
    "    - when we are interested in minimizing the error of predictions for a certain sub-group of the samples more than the general error (by giving this sub-group a higher sample_weight than the rest of the data)\n",
    "    - the loss for this particular sub-group then results often smaller compared to only train on the samples that we are interested in because we take the richness of all the data into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m scoring \u001b[38;5;241m=\u001b[39m get_scorer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# this is to show, not the real one used\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# sample_weight=[0.4, 0.3, 0.6, 0.8, 0.5]\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRidgeCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/inspect.py:3259\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3257\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/inspect.py:3248\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3246\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m   3247\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3249\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3250\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "# leave out blunt attempt, because its confusing?\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "scoring = get_scorer(\"neg_mean_squared_error\")\n",
    "\n",
    "# this is to show, not the real one used:\n",
    "# sample_weight=[0.4, 0.3, 0.6, 0.8, 0.5]\n",
    "\n",
    "cross_validate(RidgeCV(scoring=scoring), X, y, groups=groups, cv=cv, sample_weight=sample_weight, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- without the routing API, we couldn't use sample_weight here, nor could we put it in a Pipeline or use it in any other nested structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using the metadata routing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py\", line 2672, in fit\n    super().fit(X, y, sample_weight=sample_weight, **params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py\", line 2436, in fit\n    grid_search.fit(X, y, **params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 1018, in fit\n    self._run_search(evaluate_candidates)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 1572, in _run_search\n    evaluate_candidates(ParameterGrid(self.param_grid))\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 976, in evaluate_candidates\n    for (cand_idx, parameters), (split_idx, (train, test)) in product(\n                                                              ^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 416, in split\n    for train, test in super().split(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 147, in split\n    for test_index in self._iter_test_masks(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 159, in _iter_test_masks\n    for test_index in self._iter_test_indices(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 602, in _iter_test_indices\n    raise ValueError(\"The 'groups' parameter should not be None.\")\nValueError: The 'groups' parameter should not be None.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m scoring \u001b[38;5;241m=\u001b[39m get_scorer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset_score_request(sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m ridge \u001b[38;5;241m=\u001b[39m RidgeCV(cv\u001b[38;5;241m=\u001b[39mGroupKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),scoring\u001b[38;5;241m=\u001b[39mscoring)\u001b[38;5;241m.\u001b[39mset_fit_request(sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, groups\u001b[38;5;241m=\u001b[39mgroups)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mridge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroups\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGroupKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m sklearn\u001b[38;5;241m.\u001b[39mset_config(enable_metadata_routing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py\", line 2672, in fit\n    super().fit(X, y, sample_weight=sample_weight, **params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py\", line 2436, in fit\n    grid_search.fit(X, y, **params)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 1018, in fit\n    self._run_search(evaluate_candidates)\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 1572, in _run_search\n    evaluate_candidates(ParameterGrid(self.param_grid))\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_search.py\", line 976, in evaluate_candidates\n    for (cand_idx, parameters), (split_idx, (train, test)) in product(\n                                                              ^^^^^^^^\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 416, in split\n    for train, test in super().split(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 147, in split\n    for test_index in self._iter_test_masks(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 159, in _iter_test_masks\n    for test_index in self._iter_test_indices(X, y, groups):\n  File \"/home/stefanie/.pyenv/versions/metadata_talk/lib/python3.12/site-packages/sklearn/model_selection/_split.py\", line 602, in _iter_test_indices\n    raise ValueError(\"The 'groups' parameter should not be None.\")\nValueError: The 'groups' parameter should not be None.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "import sklearn\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "\n",
    "scoring = get_scorer(\"neg_mean_squared_error\").set_score_request(sample_weight=True)\n",
    "\n",
    "ridge = RidgeCV(cv=GroupKFold(n_splits=2),scoring=scoring).set_fit_request(sample_weight=True).fit(X, y, sample_weight=sample_weight, groups=groups)\n",
    "\n",
    "cross_validate(\n",
    "    ridge,\n",
    "    X,\n",
    "    y,\n",
    "    params={\"sample_weight\": sample_weight, \"groups\": groups},\n",
    "    cv=GroupKFold(n_splits=2),\n",
    "    scoring=scoring,\n",
    ")\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- explain:\n",
    "    - scorer take sample weight (scoring= param is only present in estimators ending in CV); the scoring then passes the metadata into the metric used in cross validation for evaluating the success with the internal validation set\n",
    "    - slitter splits CV and is mainly interested in groups\n",
    "\n",
    "- summing up: with metadata routing API:\n",
    "    - we can pass sample_weight and groups through several levels of estimators and pipes in scikit-learn\n",
    "    - we can combine objects from other libraries with scikit-learn estimators while still passing their metadata\n",
    "    - we can define our own custom metrics using self defined metadata \n",
    "    - and use it in a special setting with [TunedThresholdClassifier](https://scikit-learn.org/dev/auto_examples/model_selection/plot_cost_sensitive_learning.html#cost-sensitive-learning-when-gains-and-costs-are-not-constant) (as we will see in the next part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_validate, GroupKFold\n",
    "\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "\n",
    "weighted_acc = make_scorer(accuracy_score).set_score_request(sample_weight=True)\n",
    "lr = LogisticRegressionCV(\n",
    "    cv=GroupKFold(n_splits=2),\n",
    "    scoring=weighted_acc\n",
    ").set_fit_request(sample_weight=True)\n",
    "cv_results = cross_validate(\n",
    "    lr,\n",
    "    X,\n",
    "    y,\n",
    "    params={\"sample_weight\": sample_weight, \"groups\": groups},\n",
    "    cv=GroupKFold(n_splits=2),\n",
    "    scoring=weighted_acc,\n",
    ")\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Further information\n",
    "\n",
    "- User Guide on Metadata Routing: </br> \n",
    "[https://scikit-learn.org/stable/metadata_routing.html#metadata-routing](https://scikit-learn.org/stable/metadata_routing.html#metadata-routing)\n",
    "\n",
    "- Developer Guide on Metadata Routing: </br> \n",
    "[https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_metadata_routing.html#metadata-routing](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_metadata_routing.html#metadata-routing)\n",
    "\n",
    "- Adrin Jalali's talk on the internal logic of metadata routing at EuroPython Conference 2023: </br> \n",
    "[https://www.youtube.com/watch?v=1rf6HI-pYq8](https://www.youtube.com/watch?v=1rf6HI-pYq8)\n",
    "\n",
    "- Blogpost by Florian Wilhelm on Inverse Probability of Treatment Weighting: </br> \n",
    "[https://florianwilhelm.info/2017/04/causal_inference_propensity_score](https://florianwilhelm.info/2017/04/causal_inference_propensity_score)\n",
    "\n",
    "- link to Vincent's VW video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
