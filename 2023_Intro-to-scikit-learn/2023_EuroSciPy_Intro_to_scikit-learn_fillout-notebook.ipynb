{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with scikit-learn\n",
    "### Notebook for participants to fill with code themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About me\n",
    "\n",
    "Stefanie Senger, Historian (PhD)\n",
    "\n",
    "- Contributor to scikit-learn\n",
    "\n",
    "- Data Science Teacher at Le Wagon\n",
    "\n",
    "- Connect with me on LinkedIn: https://www.linkedin.com/in/stefaniesenger/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop outline (90 min.)\n",
    "\n",
    "- Machine Learning 101\n",
    "\n",
    "- What is scikit-learn?\n",
    "\n",
    "- Practical Part\n",
    "\n",
    "  - Predictive modeling pipeline\n",
    "\n",
    "  - Evaluation of models\n",
    "\n",
    "  - Hyperparameter tuning\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "Link to full notebook without gaps for participants: </br>\n",
    "\n",
    "https://github.com/StefanieSenger/Talks/blob/main/2023_EuroSciPy/2023_EuroSciPy_Intro_to_scikit-learn_full.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Idea: \n",
    "\n",
    "### to learn from past data --> make predictions for future data\n",
    "\n",
    "    We assume there is some structure in the data that is not purely coincidental.\n",
    "    We further assume, that this structure is going to reoccur in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Machine Learning\n",
    "\n",
    "![Regression-vs-Classification](images/Regression-vs-Classification.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)\n",
    "\n",
    "    - Regression: target is continuous (something to measure)\n",
    "    - Classification: target is a class (bucket)\n",
    "    - Unsupervised Learning: no target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn's modelling workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from sklearn.some_module import SomeModel\n",
    "\n",
    "model = SomeModel()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_new)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learns modelling workflow\n",
    "\n",
    "![Model.fit](images/api_diagram-predictor.fit.svg)\n",
    "\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learns modelling workflow\n",
    "\n",
    "![Model.predict](images/api_diagram-predictor.predict.svg)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn's modelling workflow\n",
    "\n",
    "![Model.score](images/api_diagram-predictor.score.svg)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Method\n",
    "![train-test-split](images/Train-Test-Split.png)\n",
    "\n",
    "Source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Train-Test-Validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Method in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "    - evens out variance in results\n",
    "\n",
    "    - scores on validation set\n",
    "\n",
    "![GridSearchCV](images/grid_search_cv.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "score = cross_validate(SomeModel(), X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff\n",
    "![Bias-Variance-Tradeoff](images/bias-variance-tradeoff.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Test Error\n",
    "\n",
    "![Model-complexity](images/model-complexity.png)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "    Scikit-learn (Sklearn) is a Machine Learning library that provides data preprocessing, modeling, and model selection tools.\n",
    "\n",
    "![Scikit-learn_logo](images/1164px-Scikit_learn_logo.svg.png)\n",
    "\n",
    "Source: [Scikit-learn](https://github.com/scikit-learn/scikit-learn/blob/main/doc/logos/scikit-learn-logo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn algorithm cheat sheet\n",
    "![Scikit-learn algorithm cheat sheet](images/Scikit-learn_machine_learning_decision_tree.png)\n",
    "\n",
    "Source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Scikit-learn_machine_learning_decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_openml(\"adult-census\", parser=\"pandas\")\n",
    "X = data['data']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal: classify people's income as \"high\" or \"low\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "![Preproc](images/preprocessing.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning columns names\n",
    "X.columns = X.columns.str.strip(\":\")\n",
    "\n",
    "# Drop columns; 'education-num' contains the same information as 'education' and 'fnlwgt' is a calculated similarity between samples\n",
    "X = X.drop(columns=['education-num', 'fnlwgt'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for impossible values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting if target is ballanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "      - Imputing missing values\n",
    "      - Encoding categorical features\n",
    "      - Scaling numerical features\n",
    "  \n",
    "</br>\n",
    "\n",
    "#### Preprocessing steps depend on the final estimator choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    observation: missing values only occur in categorical data</br>\n",
    "    -> we will take this into account when we impute values \n",
    "\n",
    "### Transformers\n",
    "\n",
    "![Transformer.fit_transform](images/api_diagram-transformer.fit_transform.svg)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Instantiate a SimpleImputer object with strategy of choice\n",
    "\n",
    "# Fit imputer\n",
    "\n",
    "# The imputed value is stored in the transformer's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect filled up DataFrame\n",
    "\n",
    "# use `sklearn.set_config(tranform_output=\"pandas\")` for scikit-learn version 1.3 and higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "    - transforming categorical data into an equivalent numerical form\n",
    "\n",
    "![OHE](images/ohe_visualization.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Instantiate the OneHotEncoder\n",
    "\n",
    "# Fit encoder\n",
    "\n",
    "# Display the detected categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming learned categories into binary columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "    - a chain of operations in a Machine Learning project (preprocessing, training, predicting)\n",
    "    - can be used to put together building blocks of several transformers and a predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build the pipeline with the different steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how OHE output looks like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "    - transforming numerical features into a common smaller range\n",
    "\n",
    "#### MinMaxScaler\n",
    "\n",
    "### $X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}$\n",
    "\n",
    "![MinMaxScaler](images/MinMaxScaler.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate scaler object\n",
    "\n",
    "# Fit MinMaxScaler\n",
    "\n",
    "# Inspect `scaler.data_range_` and other learned attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how MinMaxScaler output looks like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer\n",
    "\n",
    "![ColumnTransformer](images/api_diagram-columntransformer.svg)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector # \"trick\", but you can also manually select columns\n",
    "\n",
    "num_transformer = MinMaxScaler()\n",
    "\n",
    "# Parallelize \"num_transformer\" and \"cat_transfomer\"\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, make_column_selector(dtype_exclude='category')),\n",
    "    ('cat_transformer', cat_transformer, make_column_selector(dtype_include='category'))\n",
    "])\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on the preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot predict, because there is no predictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "    - a chain of operations in a Machine Learning project (preprocessing, training, predicting)\n",
    "    - can be used to put together building blocks of several transformers and a predictive model\n",
    "\n",
    "![Pipeline](images/pipeline.png)\n",
    "\n",
    "Source: [Le Wagon Data Science Curriculum](https://www.lewagon.com/)\n",
    "\n",
    "    - output of transformer is input into predictor\n",
    "    - call a pipeline the same way you would call the last added estimator\n",
    "\n",
    "Pipelines are powerful because they:\n",
    "\n",
    "    - make your workflow much easier to read and understand\n",
    "    - enforce the implementation and order of steps in your project\n",
    "    - make your work reproducible and deployable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Build the pipeline combining preprocessor and predictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Transformers\n",
    "num_transformer = MinMaxScaler()\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('ohe', OneHotEncoder(drop = \"if_binary\", sparse_output = False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, make_column_selector(dtype_exclude='category')),\n",
    "    ('cat_transformer', cat_transformer, make_column_selector(dtype_include='category'))\n",
    "])\n",
    "\n",
    "# Pipeline with predictor\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The pipeline becomes an estimator.\n",
    "\n",
    "    On it we can:\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    pipeline.score(X_test, y_test)\n",
    "\n",
    "    pipeline.predict(X_new)\n",
    "\n",
    "    ... and tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and predicting untuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score on untuned model with default scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking with DummyClassifier (makes predictions that ignore the input features\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with class prevalence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tunable params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "    - allows us to check, which combination of preprocessing/modeling hyperparameters works best\n",
    "\n",
    "![ChangingStuff](images/changing_stuff.png)\n",
    "\n",
    "Source: [Introduction to scikit-learn by Olivier Grisel](http://ogrisel.github.io/decks/2017_intro_sklearn/#1)\n",
    "\n",
    "![GridSeachCV](images/grid_vs_random_search.svg)\n",
    "\n",
    "Source: [Inria Scikit-learn MOOC](https://inria.github.io/scikit-learn-mooc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {\n",
    "    'param1': [0.01, 0.1, 1], \n",
    "    'param2': [0.2, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    SomeModel(),\n",
    "    grid, \n",
    "    scoring = ['scoring_metrics'],\n",
    "    cv = 5,\n",
    ") \n",
    "\n",
    "# Fit data to Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best params\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {\n",
    "    'preprocessor__num_transformer__feature_range': [(0,1), (0,2)], \n",
    "    'preprocessor__cat_transformer__ohe__min_frequency': [0.02, 0.05],\n",
    "    'logreg__C': np.logspace(-3, 3, num=10)\n",
    "}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    grid, \n",
    "    scoring = 'accuracy',\n",
    "    cv = 5,\n",
    ") \n",
    "\n",
    "# Fit data to Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best params\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring on best estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect grid_search\n",
    "pd.DataFrame(grid_search.cv_results_)[['param_logreg__C', 'param_preprocessor__num_transformer__feature_range', 'param_preprocessor__cat_transformer__ohe__min_frequency', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not gotten enough yet?\n",
    "\n",
    "#### Have a look at our scikit-learn MOOC: https://inria.github.io/scikit-learn-mooc/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for your attention!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon_current",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
